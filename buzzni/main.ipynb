{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["import os\n","import datetime\n","\n","import IPython\n","import IPython.display\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import tensorflow as tf\n","\n","mpl.rcParams['figure.figsize'] = (8, 6)\n","mpl.rcParams['axes.grid'] = False\n","\n","BASE_DIR = os.path.dirname(os.path.abspath(__file__))\n","DATA_DIR = os.path.join(BASE_DIR, 'data')\n","LOG_DIR = os.path.join(BASE_DIR, 'log')\n","MODEL_DIR = os.path.join(BASE_DIR, 'model')\n","\n","def preprocessing_dataframe(dataset):\n","    PREPROCESSING_COLS = ['a','b','c','d','e','f','g','h','Y']\n","    prep_df = {}\n","    \n","    START_DATE = dataset['date'].min()\n","    END_DATE = dataset['date'].max()\n","    \n","    del dataset['idx']\n","    dataset.set_index('date', inplace=True)\n","\n","    for date in pd.date_range(start=START_DATE, end=END_DATE).format(formatter=lambda x:x.strftime('%Y-%m-%d')):\n","        prep_df[date] = dataset.loc[date, PREPROCESSING_COLS].sum()\n","    \n","    pref_df = pd.DataFrame(prep_df).transpose()\n","\n","    return pref_df\n","\n","def df_to_dataset(dataframe, window_size=5):\n","    #수정 필요\n","    FEAUTRES_COLS = ['a','b','c','d','e','f','g','h']\n","    LABELS_COLS = ['Y']\n","\n","    START_DATE = dataframe.index.min()\n","    END_DATE = dataframe.index.max()\n","\n","    list_feature = np.array(dataframe.loc[START_DATE:END_DATE, FEAUTRES_COLS])\n","    list_bable = np.array(dataframe.loc[START_DATE:END_DATE, LABELS_COLS])\n","\n","    return list_feature, list_bable\n","\n","def dataset_normalization():\n","    return 0\n","\n","class TimeWindow():\n","    split_window = 0\n","    \"\"\"\n","        TimeWindow\n","    \"\"\"\n","    def __init__(self,  train_df, valid_df, test_df, input_width, label_width, shift, label_columns=None):\n","        \"\"\"\n","            Prams\n","                @train_df -> 트레이닝 데이터 프레임\n","                @valid_df -> 검증 데이터 프레임\n","                @test_df -> 테스트 테이터 프레임\n","                @input_width -> 입력 값 갯수, 여기서는 입력된 Timeseries 값 예를들어 1일 경우에는 1일치의 데이터\n","                @lable_width -> 검출하고자 하는 데이터 갯수, 여기서는 예측할 Timeseries 값 예를들어 2일 경우에는 2일치의 예측 데이터를 도출\n","                @shift -> 몇일 후 데이터를 뽑을 것인가 지정\n","                @label_columns -> 예측된 데이터로부터 검증할 값을 지정, 해당 과제는 'Y' 값만을 도출하면 됨\n","            \n","            i.e.,\n","                TEMP = TimeWindow(train_df, valid_df, test_df, input_width = 5, label_width = 2, shift=7, label_columns=['Y'])\n","                전처리된 Train, Valid, Test 데이터 프레임을 입력 받고, Input_width(=5) 5일간 데이터를 통해서 shift(=7) 7일 뒤인 label_width(=2) 2일간 데이터를 예측할 수 있도록 Window를 생성한다.\n","\n","        \"\"\"\n","        self.input_width = input_width\n","        self.label_width = label_width\n","        self.shift = shift\n","        self.train_df = train_df\n","        self.valid_df = valid_df\n","        self.test_df = test_df\n","        # 입력값을 클래스의 변수로 저장\n","\n","        self.total_window_size = input_width + shift\n","        # total_window_size는 \n","        \n","        self.label_columns =label_columns\n","        if label_columns is not None:\n","            self.label_columns_indices = {name: i for i, name in enumerate(label_columns) }\n","            # 도출할 값을 리스트로 변환\n","        # print(self.label_columns_indices)\n","\n","        self.column_indices = { name : idx for idx, name in enumerate(train_df.columns) }\n","        # 학습할 데이터 프레임으로부터 컬럼값들을 저장\n","        # print(self.column_indices)\n","        \n","        self.input_slice = slice(0, input_width)\n","        # 처음부터 input_width 까지 인덱스를 잘라냄, 즉 몇일 데이터를 입력할 것인가 지정\n","        \n","        self.input_indices = np.arange(self.total_window_size)[self.input_slice]\n","        # Shift를 포함한 전체 TimeWindowSize에서 학습할 시간열로 지정된 것만큼 잘라내서 저장한다.\n","\n","        self.label_start = self.total_window_size - self.label_width\n","        # label_Start 전체 TimeWindowSize에서 도출해내고자 하는 값을 가지고 있는 인덱스에서 부터 시작하도록 지정\n","        self.labels_slice = slice(self.label_start, None)\n","        # 도출하고자 하는 시간열에 대한 시작 지점으로부터 끝까지\n","        self.label_indices = np.arange(self.total_window_size)[self.labels_slice]\n","\n","    def __repr__(self):\n","        return '\\n'.join([\n","        f'Total window size: {self.total_window_size}',\n","        f'Input indices: {self.input_indices}',\n","        f'Label indices: {self.label_indices}',\n","        f'Label column name(s): {self.label_columns}'])\n","\n","def split_window(window, features):\n","    print(features)\n","    \"\"\"\n","        Params\n","            @features (batch, time, features)\n","                batch\n","                time\n","                features\n","        Return\n","            @inputs (batch, time, features)\n","            @labels (batch, time, label)\n","    \"\"\"\n","    inputs = features[:, window.input_slice, :]\n","    print(inputs)\n","    # 학습할 데이터들\n","    labels = features[:, window.labels_slice, :]\n","    # 검증할 데이터들\n","\n","    if window.label_columns is not None:\n","        labels = tf.stack([labels[:, :, window.column_indices[name]] for name in window.label_columns],axis=-1)\n","    # 검증할 데이터에 대한 값을 지정\n","\n","    inputs.set_shape([None, window.input_width, None])\n","    labels.set_shape([None, window.label_width, None])\n","    print(inputs)\n","    return inputs, labels\n","        \n","def make_dataset(window, data):\n","    data = np.array(data, dtype=np.float32)\n","    ds = tf.keras.preprocessing.timeseries_dataset_from_array(\n","        data=data,\n","        targets=None,\n","        sequence_length=window.total_window_size,\n","        sequence_stride=1,\n","        shuffle=True,\n","        batch_size=32,\n","    )\n","    print(data)\n","    \n","    return ds\n","\n","if __name__ == \"__main__\":\n","    userlog = pd.read_csv(os.path.join(DATA_DIR, 'log_1907.csv'),header=0, parse_dates=['date'], date_parser=lambda x : pd.to_datetime(x, format='%Y-%m-%d'))\n","    df = preprocessing_dataframe(userlog)\n","    # print(df.head())\n","\n","    column_indices = {name : idx for idx, name in enumerate(df.columns)}\n","    NUMBER_TIME = len(df)\n","    # 시계열 데이터의 날짜 수\n","\n","    NUMBER_FEATURE = df.shape[1]\n","    # Feature의 갯수 -> [a ,b ,c ,d, ,e, f, g, h]\n","    # print(NUMBER_FEATURE)\n","\n","    train_df = df[0:int(NUMBER_TIME*0.7)]\n","    # 트레이닝 셋 ( 70 % )\n","\n","    valid_df = df[int(NUMBER_TIME*0.7):int(NUMBER_TIME*0.9)]\n","    # 검증 셋 ( 20 % )\n","\n","    test_df = df[int(NUMBER_TIME*0.9):]\n","    # 테스트 셋 ( 10 % )\n","\n","    train_mean = train_df.mean()\n","    train_std = train_df.std()\n","\n","    train_df = (train_df - train_mean) / train_std\n","    valid_df = (valid_df - train_mean) / train_std\n","    test_df = (test_df - train_mean) / train_std\n","    \n","    single_step = TimeWindow(train_df, valid_df, test_df, input_width = 5, label_width = 2, shift=2, label_columns=['Y'])\n","    \n","    \"\"\"\n","        i.e.,\n","            TEMP = TimeWindow(train_df, valid_df, test_df, input_width = 5, label_width = 2, shift=2, label_columns=['Y'])\n","            전처리된 Train, Valid, Test 데이터 프레임을 입력 받고, Input_width(=5) 5일간 데이터를 통해서 shift(=2) 2일 뒤인 label_width(=2) 2일간 데이터를 예측할 수 있도록 Window를 생성한다.\n","    \"\"\"\n","    single_step\n","    \n","    \n","\n","    # print(np.array(train_df[:w1.total_window_size]))\n","    # print(np.array(train_df[:w1.total_window_size]).shape)\n","    \"\"\"\n","        ( N, M ) => Train_df에 있는 M개의 컬럼들의 대한 데이터를 N일에 대한 리스트로 나타낸것\n","        ( 12, 9 ) \n","            train_df에 있는 row 12개에 대해서 컬럼 column 값을 저장하고 있는 리스트\n","    \"\"\"\n","    # example_window = tf.stack([\n","    #                 np.array(train_df[:w1.total_window_size]),\n","    #                 # 0 ~ 7\n","    #                 np.array(train_df[1:1+w1.total_window_size]),\n","    #                 # 1 ~ 8\n","    #                 np.array(train_df[2:2+w1.total_window_size])\n","    #                 # 2 ~ 9\n","    #             ])\n","    \"\"\"\n","        [train_df[:w1.total_window_size]]\n","        날짜에 해당되는 a~Y까지 컬럼들을 배열 형태로 만들어서 저장한다. 즉, [ [1일에 대한 a~Y 값 리스트], [2일에 대한 a~Y 값 리스트], ... [N일에 대한 a~Y 값 리스트]]\n","        tf.stack\n","\n","    \"\"\"\n","     \n","    # example_inputs, example_labels = w1.split_window(example_window)\n","\n","    # print('All shapes are: (batch, time, features)')\n","    # print(f'Window shape: {example_window.shape}')\n","    # print(f'Inputs shape: {example_inputs.shape}')\n","    # print(f'labels shape: {example_labels.shape}')\n","\n","    # for example_inputs, example_labels in w1.train().take(1):\n","    #     print(f'Inputs shape (batch, time, features): {example_inputs.shape}')\n","    #     print(f'Labels shape (batch, time, features): {example_labels.shape}')\n",""]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}